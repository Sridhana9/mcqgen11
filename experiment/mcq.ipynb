{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d883d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "import traceback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0226a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bc6e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    task=\"text-generation\",  # âœ… required\n",
    "    temperature=0.5,\n",
    "    max_new_tokens=1024,\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f23cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample JSON format for MCQs\n",
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b3621d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for quiz generation\n",
    "TEMPLATE = \"\"\"\n",
    "Text: {text}\n",
    "\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz of {number} multiple choice questions for {subject} students in a {tone} tone. \n",
    "\n",
    "Make sure the questions are not repeated and all questions are directly based on the text.\n",
    "Ensure the format matches the RESPONSE_JSON below. Create exactly {number} MCQs.\n",
    "\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef8009d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09ef2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1643833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for evaluating the quiz quality\n",
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian and writer. Given a Multiple Choice Quiz for {subject} students,\\\n",
    "you need to evaluate the complexity of the quiz and provide a short 50-word analysis.\n",
    "\n",
    "If the quiz is too complex or not well-suited for the students, update the questions and modify the tone accordingly.\n",
    "\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Provide your expert review of the quiz:\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66ff4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],\n",
    "    template=TEMPLATE2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87e32787",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b163b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined chain\n",
    "generate_evaluate_chain = SequentialChain(\n",
    "    chains=[quiz_chain, review_chain],\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    output_variables=[\"quiz\", \"review\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "890adcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input content\n",
    "file_path = r\"C:\\Users\\sridh\\mcqgen\\data.txt\"\n",
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c85e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "NUMBER = 5\n",
    "SUBJECT = \"biology\"\n",
    "TONE = \"simple\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfeffcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text: Biology is the scientific study of life.[1][2][3] It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field.[1][2][3] For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life.[1][2][3] Energy processing is also important to life as it allows organisms to move, grow, and reproduce.[1][2][3] Finally, all organisms are able to regulate their own internal environments.[1][2][3][4][5]\n",
      "\n",
      "Biologists are able to study life at multiple levels of organization,[1] from the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations.[1][6] Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use.[7][8][9] Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.[1]\n",
      "\n",
      "Life on Earth, which emerged more than 3.7 billion years ago,[10] is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment.\n",
      "\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz of 5 multiple choice questions for biology students in a simple tone. \n",
      "\n",
      "Make sure the questions are not repeated and all questions are directly based on the text.\n",
      "Ensure the format matches the RESPONSE_JSON below. Create exactly 5 MCQs.\n",
      "\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sridh\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert English grammarian and writer. Given a Multiple Choice Quiz for biology students,you need to evaluate the complexity of the quiz and provide a short 50-word analysis.\n",
      "\n",
      "If the quiz is too complex or not well-suited for the students, update the questions and modify the tone accordingly.\n",
      "\n",
      "Quiz_MCQs:\n",
      "\n",
      "### MCQs\n",
      "{\n",
      "\"1\": {\"mcq\": \"Which scientific discipline is the study of life?\", \"options\": {\"a\": \"Physics\", \"b\": \"Biology\", \"c\": \"Chemistry\", \"d\": \"Geology\"}, \"correct\": \"b\"},\n",
      "\"2\": {\"mcq\": \"Which of the following is a major theme in the study of biology?\", \"options\": {\"a\": \"The study of the Earth's interior\", \"b\": \"The study of the properties of matter\", \"c\": \"The study of heredity and evolution\", \"d\": \"The study of the properties of light\"}, \"correct\": \"c\"},\n",
      "\"3\": {\"mcq\": \"What is the smallest unit of life?\", \"options\": {\"a\": \"Cell\", \"b\": \"Organelle\", \"c\": \"Gene\", \"d\": \"Molecule\"}, \"correct\": \"c\"},\n",
      "\"4\": {\"mcq\": \"Which of the following is a major role of organisms in an ecosystem?\", \"options\": {\"a\": \"The conversion of sunlight into food\", \"b\": \"The conversion of food into waste\", \"c\": \"The conversion of waste into food\", \"d\": \"The conversion of water into air\"}, \"correct\": \"a\"},\n",
      "\"5\": {\"mcq\": \"Which of the following is a major theme in the study of biology?\", \"options\": {\"a\": \"The study of the properties of matter\", \"b\": \"The study of the structure and function of cells\", \"c\": \"The study of the structure and behavior of organisms\", \"d\": \"The study of the origins and diversity of life on Earth\"}, \"correct\": \"d\"}\n",
      "}\n",
      "\n",
      "These MCQs cover various aspects of biology as mentioned in the text, and are directly based on the information provided. They are also formatted according to the RESPONSE_JSON structure.\n",
      "\n",
      "Provide your expert review of the quiz:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sridh\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run the chain\n",
    "response = generate_evaluate_chain(\n",
    "    {\n",
    "        \"text\": TEXT,\n",
    "        \"number\": NUMBER,\n",
    "        \"subject\": SUBJECT,\n",
    "        \"tone\": TONE,\n",
    "        \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4351f5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
