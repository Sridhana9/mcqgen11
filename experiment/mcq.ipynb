{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4d883d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "import traceback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0226a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2bc6e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    task=\"text-generation\",  # ✅ required\n",
    "    temperature=0.5,\n",
    "    max_new_tokens=1024,\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5f23cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample JSON format for MCQs\n",
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b3621d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for quiz generation\n",
    "TEMPLATE = \"\"\"\n",
    "Text: {text}\n",
    "\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz of {number} multiple choice questions for {subject} students in a {tone} tone. \n",
    "\n",
    "Make sure the questions are not repeated and all questions are directly based on the text.\n",
    "Ensure the format matches the RESPONSE_JSON below. Create exactly {number} MCQs.\n",
    "\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef8009d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09ef2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1643833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for evaluating the quiz quality\n",
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian and writer. Given a Multiple Choice Quiz for {subject} students,\\\n",
    "you need to evaluate the complexity of the quiz and provide a short 50-word analysis.\n",
    "\n",
    "If the quiz is too complex or not well-suited for the students, update the questions and modify the tone accordingly.\n",
    "\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Provide your expert review of the quiz:\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66ff4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],\n",
    "    template=TEMPLATE2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87e32787",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b163b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined chain\n",
    "generate_evaluate_chain = SequentialChain(\n",
    "    chains=[quiz_chain, review_chain],\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    output_variables=[\"quiz\", \"review\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "890adcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input content\n",
    "file_path = r\"C:\\Users\\sridh\\mcqgen\\data.txt\"\n",
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c85e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "NUMBER = 5\n",
    "SUBJECT = \"biology\"\n",
    "TONE = \"simple\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bfeffcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text: Biology is the scientific study of life.[1][2][3] It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field.[1][2][3] For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life.[1][2][3] Energy processing is also important to life as it allows organisms to move, grow, and reproduce.[1][2][3] Finally, all organisms are able to regulate their own internal environments.[1][2][3][4][5]\n",
      "\n",
      "Biologists are able to study life at multiple levels of organization,[1] from the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations.[1][6] Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use.[7][8][9] Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.[1]\n",
      "\n",
      "Life on Earth, which emerged more than 3.7 billion years ago,[10] is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment.\n",
      "\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz of 5 multiple choice questions for biology students in a simple tone. \n",
      "\n",
      "Make sure the questions are not repeated and all questions are directly based on the text.\n",
      "Ensure the format matches the RESPONSE_JSON below. Create exactly 5 MCQs.\n",
      "\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sridh\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert English grammarian and writer. Given a Multiple Choice Quiz for biology students,you need to evaluate the complexity of the quiz and provide a short 50-word analysis.\n",
      "\n",
      "If the quiz is too complex or not well-suited for the students, update the questions and modify the tone accordingly.\n",
      "\n",
      "Quiz_MCQs:\n",
      "\n",
      "### MCQs\n",
      "{\"1\": {\"mcq\": \"Which scientific field studies the fundamental biological processes that occur in living organisms?\", \"options\": {\"a\": \"Physics\", \"b\": \"Chemistry\", \"c\": \"Biology\", \"d\": \"Mathematics\"}, \"correct\": \"c\"}, \"2\": {\"mcq\": \"Which major theme of biology explains the unity and diversity of life?\", \"options\": {\"a\": \"Cellular structure and function\", \"b\": \"Evolution\", \"c\": \"Metabolism\", \"d\": \"Reproduction\"}, \"correct\": \"b\"}, \"3\": {\"mcq\": \"Which of the following is not a major theme of biology?\", \"options\": {\"a\": \"Cellular structure and function\", \"b\": \"Energy processing\", \"c\": \"Regulation of internal environments\", \"d\": \"Photosynthesis\"}, \"correct\": \"d\"}, \"4\": {\"mcq\": \"Which organisms do not have a nucleus in their cells?\", \"options\": {\"a\": \"Archaea\", \"b\": \"Bacteria\", \"c\": \"Plants\", \"d\": \"Fungi\"}, \"correct\": \"b\"}, \"5\": {\"mcq\": \"Which of the following organisms is not a part of the eukaryotic domain?\", \"options\": {\"a\": \"Fungi\", \"b\": \"Plants\", \"c\": \"Protists\", \"d\": \"Animals\"}, \"correct\": \"c\"}}\n",
      "\n",
      "Provide your expert review of the quiz:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sridh\\mcqgen\\env\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run the chain\n",
    "response = generate_evaluate_chain(\n",
    "    {\n",
    "        \"text\": TEXT,\n",
    "        \"number\": NUMBER,\n",
    "        \"subject\": SUBJECT,\n",
    "        \"tone\": TONE,\n",
    "        \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4351f5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Biology is the scientific study of life.[1][2][3] It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field.[1][2][3] For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life.[1][2][3] Energy processing is also important to life as it allows organisms to move, grow, and reproduce.[1][2][3] Finally, all organisms are able to regulate their own internal environments.[1][2][3][4][5]\\n\\nBiologists are able to study life at multiple levels of organization,[1] from the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations.[1][6] Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use.[7][8][9] Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.[1]\\n\\nLife on Earth, which emerged more than 3.7 billion years ago,[10] is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment.',\n",
       " 'number': 5,\n",
       " 'subject': 'biology',\n",
       " 'tone': 'simple',\n",
       " 'response_json': '{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '\\n### MCQs\\n{\"1\": {\"mcq\": \"Which scientific field studies the fundamental biological processes that occur in living organisms?\", \"options\": {\"a\": \"Physics\", \"b\": \"Chemistry\", \"c\": \"Biology\", \"d\": \"Mathematics\"}, \"correct\": \"c\"}, \"2\": {\"mcq\": \"Which major theme of biology explains the unity and diversity of life?\", \"options\": {\"a\": \"Cellular structure and function\", \"b\": \"Evolution\", \"c\": \"Metabolism\", \"d\": \"Reproduction\"}, \"correct\": \"b\"}, \"3\": {\"mcq\": \"Which of the following is not a major theme of biology?\", \"options\": {\"a\": \"Cellular structure and function\", \"b\": \"Energy processing\", \"c\": \"Regulation of internal environments\", \"d\": \"Photosynthesis\"}, \"correct\": \"d\"}, \"4\": {\"mcq\": \"Which organisms do not have a nucleus in their cells?\", \"options\": {\"a\": \"Archaea\", \"b\": \"Bacteria\", \"c\": \"Plants\", \"d\": \"Fungi\"}, \"correct\": \"b\"}, \"5\": {\"mcq\": \"Which of the following organisms is not a part of the eukaryotic domain?\", \"options\": {\"a\": \"Fungi\", \"b\": \"Plants\", \"c\": \"Protists\", \"d\": \"Animals\"}, \"correct\": \"c\"}}',\n",
       " 'review': '\\nThe quiz is well-structured and appropriate for biology students. The questions are clear, concise, and cover essential topics in biology. The use of multiple-choice format makes it easier for students to identify correct answers. However, some students may find question 5 challenging, as it requires knowledge of the domain of Protists, which can be less familiar to some students. Overall, the quiz is suitable for the intended audience and provides a good assessment of their foundational knowledge in biology.'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f42025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "quiz_raw = response.get(\"quiz\", \"\")\n",
    "\n",
    "# Try to find the first valid JSON-looking object\n",
    "match = re.search(r\"({.*})\", quiz_raw, re.DOTALL)\n",
    "if match:\n",
    "    try:\n",
    "        quiz = json.loads(match.group(1))\n",
    "    except Exception as e:\n",
    "        print(\"❌ JSON loading failed:\", e)\n",
    "        quiz = {}\n",
    "else:\n",
    "    print(\"❌ No JSON object found in quiz response\")\n",
    "    quiz = {}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e7faffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [f\"{option}: {option_value}\" for option, option_value in value[\"options\"].items()]\n",
    "    )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b0bdc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quiz Review:\n",
      " \n",
      "The quiz is well-structured and appropriate for biology students. The questions are clear, concise, and cover essential topics in biology. The use of multiple-choice format makes it easier for students to identify correct answers. However, some students may find question 5 challenging, as it requires knowledge of the domain of Protists, which can be less familiar to some students. Overall, the quiz is suitable for the intended audience and provides a good assessment of their foundational knowledge in biology.\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "quiz_df = pd.DataFrame(quiz_table_data)\n",
    "quiz_df.to_csv(\"mcq_output.csv\", index=False)\n",
    "\n",
    "\n",
    "# Print review\n",
    "print(\"\\nQuiz Review:\\n\", response.get(\"review\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
