{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d883d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "import traceback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0226a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bc6e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    temperature=0.5,\n",
    "    max_new_tokens=1024,\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f23cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample JSON format for MCQs\n",
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3621d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for quiz generation\n",
    "TEMPLATE = \"\"\"\n",
    "Text: {text}\n",
    "\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz of {number} multiple choice questions for {subject} students in a {tone} tone. \n",
    "\n",
    "Make sure the questions are not repeated and all questions are directly based on the text.\n",
    "Ensure the format matches the RESPONSE_JSON below. Create exactly {number} MCQs.\n",
    "\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "\n",
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)\n",
    "\n",
    "\n",
    "# Prompt for evaluating the quiz quality\n",
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian and writer. Given a Multiple Choice Quiz for {subject} students,\\\n",
    "you need to evaluate the complexity of the quiz and provide a short 50-word analysis.\n",
    "\n",
    "If the quiz is too complex or not well-suited for the students, update the questions and modify the tone accordingly.\n",
    "\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Provide your expert review of the quiz:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],\n",
    "    template=TEMPLATE2\n",
    ")\n",
    "\n",
    "\n",
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)\n",
    "\n",
    "\n",
    "# Combined chain\n",
    "generate_evaluate_chain = SequentialChain(\n",
    "    chains=[quiz_chain, review_chain],\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    output_variables=[\"quiz\", \"review\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Read input content\n",
    "file_path = r\"C:\\Users\\sridh\\mcqgen\\data.txt\"\n",
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()\n",
    "\n",
    "\n",
    "# Configuration\n",
    "NUMBER = 5\n",
    "SUBJECT = \"biology\"\n",
    "TONE = \"simple\"\n",
    "# Run the chain\n",
    "response = generate_evaluate_chain(\n",
    "    {\n",
    "        \"text\": TEXT,\n",
    "        \"number\": NUMBER,\n",
    "        \"subject\": SUBJECT,\n",
    "        \"tone\": TONE,\n",
    "        \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Extract quiz and convert to table\n",
    "quiz = response.get(\"quiz\")\n",
    "try:\n",
    "    quiz = json.loads(quiz)\n",
    "except Exception as e:\n",
    "    print(\"Failed to parse quiz JSON:\", e)\n",
    "    print(\"Raw quiz response:\\n\", quiz)\n",
    "    quiz = {}\n",
    "\n",
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [f\"{option}: {option_value}\" for option, option_value in value[\"options\"].items()]\n",
    "    )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})\n",
    "\n",
    "\n",
    "# Save to CSV\n",
    "quiz_df = pd.DataFrame(quiz_table_data)\n",
    "quiz_df.to_csv(\"mcq_output.csv\", index=False)\n",
    "\n",
    "\n",
    "# Print review\n",
    "print(\"\\nQuiz Review:\\n\", response.get(\"review\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
